{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I will ask user to input queries and then I would find the relevant documents from the indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "def isValid(query):\n",
    "    #there can be maximum of three words in a boolean query so there would be max of 5 words including operators(AND,OR,NOT)\n",
    "    query = query.lower().strip() #remove any extra spaces\n",
    "    if not query:\n",
    "        print(\"Query cannot be empty\")\n",
    "        return False\n",
    "\n",
    "    words = query.split()\n",
    "    if len(words)>5:\n",
    "        print(\"Only 3 words allowed at Max\")\n",
    "        return False\n",
    "    \n",
    "    for word in words:\n",
    "        if not word.isalpha():\n",
    "            print(\"Only alphabets allowed\")\n",
    "            return False\n",
    "\n",
    "    operators = {'and','or','not'}\n",
    "    for i in range(len(words)):\n",
    "        if i%2==1:  #operators would be at odd positions\n",
    "            if words[i] not in operators:\n",
    "                print(\"Invalid Operators or invalid format\")\n",
    "                return False\n",
    "        elif i%2==0:\n",
    "            if words[i] in operators:\n",
    "                print(\"Operator at wrong position\")\n",
    "                return False\n",
    "    terms = []\n",
    "    ops = []\n",
    "    for word in words:\n",
    "        if word in operators:\n",
    "            ops.append(word)\n",
    "        else:\n",
    "            terms.append(ps.stem(word))\n",
    "\n",
    "    return terms,ops,True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query has been validated now I will use intersect algorithm(taught in the course) to retrieve the correct postings. I will show two pointer approach for and operation and then I will utilize set functions to show how other queries are processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDocs(terms,ops,invertedIndex):\n",
    "    all_docs = set()\n",
    "    for doc_list in invertedIndex.values():\n",
    "        all_docs.update(doc_list)\n",
    "\n",
    "    if len(terms) == 1:\n",
    "        if terms[0] in invertedIndex:\n",
    "            return invertedIndex[terms[0]]\n",
    "        else:\n",
    "            print(f\"Term: {terms[0]} not found in documents\")\n",
    "            return []\n",
    "    elif len(terms) == 2:\n",
    "        l1 = []\n",
    "        l2 = []\n",
    "        if terms[0] in invertedIndex:\n",
    "            l1 = invertedIndex[terms[0]]\n",
    "        else:\n",
    "            print(f\"Term: {terms[0]} not found in documents\")\n",
    "            return []\n",
    "        if terms[1] in invertedIndex:\n",
    "            l2 = invertedIndex[terms[1]]\n",
    "        else:\n",
    "            print(f\"Term: {terms[1]} not found in documents\")\n",
    "            return []\n",
    "        if len(ops) == 1:\n",
    "            if ops[0] == 'and':\n",
    "                ans = []\n",
    "                i,j = 0,0 #Two pointer approach\n",
    "                while i<len(l1) and j<len(l2):\n",
    "                    if l1[i] == l2[j]:\n",
    "                        ans.append(l1[i])\n",
    "                        i+=1\n",
    "                        j+=1\n",
    "                    elif l1[i]<l2[j]:\n",
    "                        i+=1\n",
    "                    else:\n",
    "                        j+=1\n",
    "                return ans\n",
    "            #Could have implemented or and not as well with two pointer but code would have been longer so i used set operations\n",
    "            if ops[0] == 'or':\n",
    "                return list(set(l1+l2))  #union\n",
    "            if ops[0] == 'not':\n",
    "                return list(set(l1)-set(l2))\n",
    "    elif len(terms) == 3:\n",
    "        l1 = []\n",
    "        l2 = []\n",
    "        l3 = []\n",
    "        if terms[0] in invertedIndex:\n",
    "            l1 = invertedIndex[terms[0]]\n",
    "        else:\n",
    "            print(f\"Term: {terms[0]} not found in documents\")\n",
    "            return []\n",
    "        if terms[1] in invertedIndex:\n",
    "            l2 = invertedIndex[terms[1]]\n",
    "        else:\n",
    "            print(f\"Term: {terms[1]} not found in documents\")\n",
    "            return []\n",
    "        if terms[2] in invertedIndex:\n",
    "            l3 = invertedIndex[terms[2]]\n",
    "        else:\n",
    "            print(f\"Term: {terms[2]} not found in documents\")\n",
    "        #Logical rule = (term1 op term2) op term 3\n",
    "        if ops[0] == 'and' and ops[1] == 'and':\n",
    "            return list(set(l1) & set(l2) & set(l3))\n",
    "\n",
    "        if ops[0] == 'and' and ops[1] == 'or':\n",
    "            return list((set(l1) & set(l2)) | set(l3))\n",
    "\n",
    "        if ops[0] == 'or' and ops[1] == 'and':\n",
    "            return list((set(l1) | set(l2)) & set(l3))\n",
    "\n",
    "        if ops[0] == 'or' and ops[1] == 'or':\n",
    "            return list(set(l1) | set(l2) | set(l3))\n",
    "\n",
    "        if ops[0] == 'and' and ops[1] == 'not':\n",
    "            return list(set(l1) & (set(l2) - set(l3)))\n",
    "\n",
    "        if ops[0] == 'or' and ops[1] == 'not':\n",
    "            return list((set(l1) | set(l2)) - set(l3))\n",
    "        \n",
    "        if ops[0] == 'not' and ops[1] == 'and':\n",
    "            return list((all_docs - set(l1)) & set(l3))\n",
    "        \n",
    "        if ops[0] == 'not' and ops[1] == 'or':\n",
    "            return list((all_docs - set(l1)) | set(l3))\n",
    "        \n",
    "        if ops[0] == 'not' and ops[1] == 'not':\n",
    "            return list(all_docs - set(l1) - set(l2))\n",
    "    return []\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now implementing mechanism for achieving proximity query finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query Validation\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def isValidProximity(query):\n",
    "    query = query.lower().strip() #remove any extra spaces\n",
    "    if not query:\n",
    "        print(\"Query cannot be empty\")\n",
    "        return False\n",
    "\n",
    "    words = query.split()\n",
    "    if len(words)!=2:\n",
    "        print(\"enter only two words\")\n",
    "        return False\n",
    "    \n",
    "    for word in words:\n",
    "        if not word.isalpha():\n",
    "            print(\"Only alphabets allowed\")\n",
    "            return False\n",
    "\n",
    "    terms = []\n",
    "    ps = PorterStemmer()\n",
    "    for word in words:\n",
    "        terms.append(ps.stem(word))\n",
    "\n",
    "    return tuple(terms),True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proximitySearch(terms,k,positionalIndex):\n",
    "\n",
    "    term1,term2 = terms\n",
    "    if term1 not in positionalIndex or term2 not in positionalIndex:\n",
    "        print(f\"Either term: {term1} or term: {term2} not found in documents\")\n",
    "        return []\n",
    "    \n",
    "    ans = set()\n",
    "    for doc in positionalIndex[term1].keys() & positionalIndex[term2].keys():  #finds common docs\n",
    "        pos1 = sorted(positionalIndex[term1][doc])\n",
    "        pos2 = sorted(positionalIndex[term2][doc])\n",
    "\n",
    "        i,j = 0,0\n",
    "        while i<len(pos1) and j<len(pos2):\n",
    "            if abs(pos1[i]-pos2[j]) <= k:\n",
    "                ans.add(doc)\n",
    "                i+=1\n",
    "            elif pos1[i]<pos2[j]:\n",
    "                i+=1\n",
    "            else:\n",
    "                j+=1\n",
    "    return list(ans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "invertedIndex = {}\n",
    "with open('22K4036_invertedIndex.txt','r') as f:\n",
    "    for line in f:\n",
    "        term,docIDs = line.strip().split(' -> ')\n",
    "        invertedIndex[term] = eval(docIDs)\n",
    "\n",
    "\n",
    "positionalIndex = {}\n",
    "with open('22K4036_positionalindex.txt','r') as f:\n",
    "    for line in f:\n",
    "        term,docIDs = line.strip().split(' -> ')\n",
    "        positionalIndex[term] = eval(docIDs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking my models against the Gold Query Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query terms are: ['imag', 'restor']\n",
      "\n",
      "[359, 375]\n",
      "------------------------------------------------------\n",
      "\n",
      "The query terms are: ['deep', 'learn']\n",
      "\n",
      "[23, 24, 174, 175, 176, 177, 213, 245, 247, 250, 254, 258, 267, 272, 273, 278, 279, 281, 325, 333, 345, 346, 347, 348, 352, 357, 358, 360, 362, 371, 373, 374, 375, 380, 381, 382, 396, 397, 401, 404, 405, 415, 421, 432, 444]\n",
      "------------------------------------------------------\n",
      "\n",
      "The query terms are: ['autoencod']\n",
      "\n",
      "[187, 273, 279, 325, 333, 405]\n",
      "------------------------------------------------------\n",
      "\n",
      "The query terms are: ['tempor', 'deep', 'learn']\n",
      "\n",
      "[358, 373, 405, 279]\n",
      "------------------------------------------------------\n",
      "\n",
      "The query terms are: ['time', 'seri']\n",
      "\n",
      "[40, 54, 110, 111, 112, 113, 158, 163, 173, 180, 181, 202, 220, 237, 238, 239, 240, 258, 277, 283, 295, 305, 350, 405, 421, 437, 438, 445]\n",
      "------------------------------------------------------\n",
      "\n",
      "The query terms are: ['time', 'seri', 'classif']\n",
      "\n",
      "[40, 237, 283, 445]\n",
      "------------------------------------------------------\n",
      "\n",
      "The query terms are: ['time', 'seri', 'classif']\n",
      "\n",
      "[4, 6, 9, 10, 16, 22, 24, 33, 34, 38, 40, 43, 45, 46, 49, 51, 54, 55, 56, 58, 59, 60, 63, 64, 66, 67, 71, 73, 75, 76, 77, 80, 84, 85, 94, 95, 98, 99, 106, 107, 110, 111, 112, 113, 120, 121, 122, 123, 125, 126, 128, 140, 143, 147, 158, 163, 164, 165, 167, 168, 169, 171, 173, 174, 175, 176, 177, 180, 181, 182, 187, 193, 197, 198, 202, 208, 210, 213, 215, 220, 228, 229, 234, 235, 236, 237, 238, 239, 240, 245, 247, 248, 249, 252, 256, 258, 259, 261, 265, 268, 272, 273, 277, 280, 283, 286, 287, 289, 295, 299, 302, 303, 305, 310, 313, 316, 317, 321, 327, 328, 334, 338, 341, 345, 348, 350, 352, 353, 354, 357, 363, 369, 371, 375, 377, 378, 382, 384, 385, 386, 387, 395, 397, 404, 405, 408, 420, 421, 424, 425, 427, 432, 437, 438, 439, 442, 445]\n",
      "------------------------------------------------------\n",
      "\n",
      "The query terms are: ['pattern']\n",
      "\n",
      "[9, 10, 18, 21, 23, 26, 30, 34, 40, 50, 73, 118, 126, 127, 139, 145, 148, 155, 180, 186, 189, 194, 201, 209, 214, 216, 230, 231, 234, 238, 279, 280, 288, 326, 343, 350, 351, 368, 369, 383, 394, 406, 412, 413, 424, 425, 429, 446, 447]\n",
      "------------------------------------------------------\n",
      "\n",
      "The query terms are: ['pattern', 'cluster']\n",
      "\n",
      "[40, 73, 180, 216, 326, 350, 351, 413, 446]\n",
      "------------------------------------------------------\n",
      "\n",
      "The query terms are: ['pattern', 'cluster', 'heart']\n",
      "\n",
      "[73]\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    query = input(\"Enter a boolean Query: \")\n",
    "    terms,ops,res = isValid(query)\n",
    "    print(f\"The query terms are: {terms}\\n\")\n",
    "    if res:\n",
    "        ans = findDocs(terms,ops,invertedIndex)\n",
    "        print(ans)\n",
    "        print(\"------------------------------------------------------\\n\")\n",
    "    else:\n",
    "        print(\"Invalid Query\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query terms are: ('neural', 'inform')\n",
      "\n",
      "[]\n",
      "------------------------------------------------------\n",
      "\n",
      "The query terms are: ('neural', 'inform')\n",
      "\n",
      "[26]\n",
      "------------------------------------------------------\n",
      "\n",
      "The query terms are: ('featur', 'track')\n",
      "\n",
      "[212, 13]\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    query = input(\"Enter a proximity Query: \")\n",
    "    terms,res = isValidProximity(query)\n",
    "    print(f\"The query terms are: {terms}\\n\")\n",
    "    k = int(input(\"Enter value of K: \"))\n",
    "    if res:\n",
    "        ans = proximitySearch(terms,k,positionalIndex)\n",
    "        print(ans)\n",
    "        print(\"------------------------------------------------------\\n\")\n",
    "    else:\n",
    "        print(\"Invalid Query\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
